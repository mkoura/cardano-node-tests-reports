{
  "uid" : "e216e68c65b5e0e4",
  "name" : "test_pool_blocks[next]",
  "fullName" : "cardano_node_tests.tests.test_blocks.TestLeadershipSchedule#test_pool_blocks",
  "historyId" : "531ec6abb32f00e98db8aeb962285fe7",
  "time" : {
    "start" : 1658628973523,
    "stop" : 1658629378253,
    "duration" : 404730
  },
  "description" : "Check that blocks were minted according to leadership schedule.\n\n        * query leadership schedule for selected pool for current epoch or next epoch\n        * wait for epoch that comes after the queried epoch\n        * get info about minted blocks in queried epoch for the selected pool\n        * compare leadership schedule with blocks that were actually minted\n        * compare db-sync records with ledger state dump\n        ",
  "descriptionHtml" : "<p>Check that blocks were minted according to leadership schedule.</p>\n<pre><code>    * query leadership schedule for selected pool for current epoch or next epoch\n    * wait for epoch that comes after the queried epoch\n    * get info about minted blocks in queried epoch for the selected pool\n    * compare leadership schedule with blocks that were actually minted\n    * compare db-sync records with ledger state dump\n</code></pre>\n",
  "status" : "failed",
  "statusMessage" : "Failed: Errors:\nSome blocks were minted in other slots than scheduled: {37507, 38023, 37129, 37770, 37262, 37774, 37775, 37270, 38044, 37278, 37407, 37154, 37538, 38054, 37288, 37934, 37936, 37553, 37811, 37558, 38071, 37304, 37947, 37316, 38086, 37977, 37217, 37353, 37100, 37357, 37491, 37876, 37623, 37371, 37243}\nLot of slots missed: {37890, 37637, 38024, 37518, 37135, 37630, 37521, 37523, 38035, 37914, 37282, 37286, 37416, 37802, 37930, 37170, 37305, 37817, 37181, 37315, 37960, 37449, 37323, 37857, 37224, 37871, 37234, 37749, 37754, 37246}",
  "statusTrace" : "self = <cardano_node_tests.tests.test_blocks.TestLeadershipSchedule object at 0x7f7201e9fa90>, skip_leadership_schedule = None\ncluster_manager = <cardano_node_tests.utils.cluster_management.ClusterManager object at 0x7f7201d490f0>, cluster_use_pool3 = <ClusterLib: protocol=cardano, tx_era=babbage>, for_epoch = 'next'\n\n    @allure.link(helpers.get_vcs_link())\n    @pytest.mark.needs_dbsync\n    @pytest.mark.parametrize(\"for_epoch\", (\"current\", \"next\"))\n    def test_pool_blocks(\n        self,\n        skip_leadership_schedule: None,\n        cluster_manager: cluster_management.ClusterManager,\n        cluster_use_pool3: clusterlib.ClusterLib,\n        for_epoch: str,\n    ):\n        \"\"\"Check that blocks were minted according to leadership schedule.\n    \n        * query leadership schedule for selected pool for current epoch or next epoch\n        * wait for epoch that comes after the queried epoch\n        * get info about minted blocks in queried epoch for the selected pool\n        * compare leadership schedule with blocks that were actually minted\n        * compare db-sync records with ledger state dump\n        \"\"\"\n        # pylint: disable=unused-argument\n        cluster = cluster_use_pool3\n        temp_template = f\"{common.get_test_id(cluster)}_{for_epoch}\"\n    \n        pool_name = cluster_management.Resources.POOL3\n        pool_rec = cluster_manager.cache.addrs_data[pool_name]\n        pool_id = cluster.get_stake_pool_id(pool_rec[\"cold_key_pair\"].vkey_file)\n    \n        if for_epoch == \"current\":\n            # wait for beginning of an epoch\n            queried_epoch = cluster.wait_for_new_epoch(padding_seconds=5)\n        else:\n            # wait for stable stake distribution for next epoch, that is last 300 slots of\n            # current epoch\n            clusterlib_utils.wait_for_epoch_interval(\n                cluster_obj=cluster,\n                start=-int(300 * cluster.slot_length),\n                stop=-10,\n                check_slot=True,\n            )\n            queried_epoch = cluster.get_epoch() + 1\n    \n        # query leadership schedule for selected pool\n        leadership_schedule = cluster.get_leadership_schedule(\n            vrf_skey_file=pool_rec[\"vrf_key_pair\"].skey_file,\n            cold_vkey_file=pool_rec[\"cold_key_pair\"].vkey_file,\n            for_next=for_epoch != \"current\",\n        )\n    \n        # wait for epoch that comes after the queried epoch\n        cluster.wait_for_new_epoch(new_epochs=1 if for_epoch == \"current\" else 2)\n    \n        # get info about minted blocks in queried epoch for the selected pool\n        minted_blocks = list(\n            dbsync_queries.query_blocks(\n                pool_id_bech32=pool_id, epoch_from=queried_epoch, epoch_to=queried_epoch\n            )\n        )\n        slots_when_minted = {r.slot_no for r in minted_blocks}\n    \n        errors: List[str] = []\n    \n        # compare leadership schedule with blocks that were actually minted\n        slots_when_scheduled = {r.slot_no for r in leadership_schedule}\n    \n        difference_scheduled = slots_when_minted.difference(slots_when_scheduled)\n        if difference_scheduled:\n            errors.append(\n                f\"Some blocks were minted in other slots than scheduled: {difference_scheduled}\"\n            )\n    \n        difference_minted = slots_when_scheduled.difference(slots_when_minted)\n        if len(difference_minted) > len(leadership_schedule) // 2:\n            errors.append(f\"Lot of slots missed: {difference_minted}\")\n    \n        # compare db-sync records with ledger state dump\n        ledger_state = clusterlib_utils.get_ledger_state(cluster_obj=cluster)\n        clusterlib_utils.save_ledger_state(\n            cluster_obj=cluster,\n            state_name=temp_template,\n            ledger_state=ledger_state,\n        )\n        blocks_before: Dict[str, int] = ledger_state[\"blocksBefore\"]\n        pool_id_dec = helpers.decode_bech32(pool_id)\n        minted_blocks_ledger = blocks_before.get(pool_id_dec) or 0\n        minted_blocks_db = len(slots_when_minted)\n        if minted_blocks_ledger != minted_blocks_db:\n            errors.append(\n                \"Numbers of minted blocks reported by ledger state and db-sync don't match: \"\n                f\"{minted_blocks_ledger} vs {minted_blocks_db}\"\n            )\n    \n        if errors:\n            err_joined = \"\\n\".join(errors)\n>           pytest.fail(f\"Errors:\\n{err_joined}\")\nE           Failed: Errors:\nE           Some blocks were minted in other slots than scheduled: {37507, 38023, 37129, 37770, 37262, 37774, 37775, 37270, 38044, 37278, 37407, 37154, 37538, 38054, 37288, 37934, 37936, 37553, 37811, 37558, 38071, 37304, 37947, 37316, 38086, 37977, 37217, 37353, 37100, 37357, 37491, 37876, 37623, 37371, 37243}\nE           Lot of slots missed: {37890, 37637, 38024, 37518, 37135, 37630, 37521, 37523, 38035, 37914, 37282, 37286, 37416, 37802, 37930, 37170, 37305, 37817, 37181, 37315, 37960, 37449, 37323, 37857, 37224, 37871, 37234, 37749, 37754, 37246}\n\n/home/martink/Source/repos/cardano-node-tests2/cardano_node_tests/tests/test_blocks.py:127: Failed",
  "flaky" : false,
  "newFailed" : false,
  "beforeStages" : [ {
    "name" : "cluster_use_pool3",
    "time" : {
      "start" : 1658628973258,
      "stop" : 1658628973521,
      "duration" : 263
    },
    "status" : "passed",
    "steps" : [ ],
    "attachments" : [ ],
    "parameters" : [ ],
    "stepsCount" : 0,
    "attachmentsCount" : 0,
    "shouldDisplayMessage" : false,
    "hasContent" : false
  }, {
    "name" : "testfile_temp_dir",
    "time" : {
      "start" : 1658628973245,
      "stop" : 1658628973245,
      "duration" : 0
    },
    "status" : "passed",
    "steps" : [ ],
    "attachments" : [ ],
    "parameters" : [ ],
    "stepsCount" : 0,
    "attachmentsCount" : 0,
    "shouldDisplayMessage" : false,
    "hasContent" : false
  }, {
    "name" : "worker_id",
    "time" : {
      "start" : 1658621560532,
      "stop" : 1658621560532,
      "duration" : 0
    },
    "status" : "passed",
    "steps" : [ ],
    "attachments" : [ ],
    "parameters" : [ ],
    "stepsCount" : 0,
    "attachmentsCount" : 0,
    "shouldDisplayMessage" : false,
    "hasContent" : false
  }, {
    "name" : "change_dir",
    "time" : {
      "start" : 1658621560531,
      "stop" : 1658621560532,
      "duration" : 1
    },
    "status" : "passed",
    "steps" : [ ],
    "attachments" : [ ],
    "parameters" : [ ],
    "stepsCount" : 0,
    "attachmentsCount" : 0,
    "shouldDisplayMessage" : false,
    "hasContent" : false
  }, {
    "name" : "close_dbconn",
    "time" : {
      "start" : 1658621560532,
      "stop" : 1658621560532,
      "duration" : 0
    },
    "status" : "passed",
    "steps" : [ ],
    "attachments" : [ ],
    "parameters" : [ ],
    "stepsCount" : 0,
    "attachmentsCount" : 0,
    "shouldDisplayMessage" : false,
    "hasContent" : false
  }, {
    "name" : "skip_leadership_schedule",
    "time" : {
      "start" : 1658628973245,
      "stop" : 1658628973258,
      "duration" : 13
    },
    "status" : "passed",
    "steps" : [ ],
    "attachments" : [ ],
    "parameters" : [ ],
    "stepsCount" : 0,
    "attachmentsCount" : 0,
    "shouldDisplayMessage" : false,
    "hasContent" : false
  }, {
    "name" : "tmp_path_factory",
    "time" : {
      "start" : 1658621560531,
      "stop" : 1658621560531,
      "duration" : 0
    },
    "status" : "passed",
    "steps" : [ ],
    "attachments" : [ ],
    "parameters" : [ ],
    "stepsCount" : 0,
    "attachmentsCount" : 0,
    "shouldDisplayMessage" : false,
    "hasContent" : false
  }, {
    "name" : "cluster_manager",
    "time" : {
      "start" : 1658628973258,
      "stop" : 1658628973258,
      "duration" : 0
    },
    "status" : "passed",
    "steps" : [ ],
    "attachments" : [ ],
    "parameters" : [ ],
    "stepsCount" : 0,
    "attachmentsCount" : 0,
    "shouldDisplayMessage" : false,
    "hasContent" : false
  }, {
    "name" : "session_autouse",
    "time" : {
      "start" : 1658621560532,
      "stop" : 1658621560532,
      "duration" : 0
    },
    "status" : "passed",
    "steps" : [ ],
    "attachments" : [ ],
    "parameters" : [ ],
    "stepsCount" : 0,
    "attachmentsCount" : 0,
    "shouldDisplayMessage" : false,
    "hasContent" : false
  }, {
    "name" : "cd_testfile_temp_dir",
    "time" : {
      "start" : 1658628973258,
      "stop" : 1658628973258,
      "duration" : 0
    },
    "status" : "passed",
    "steps" : [ ],
    "attachments" : [ ],
    "parameters" : [ ],
    "stepsCount" : 0,
    "attachmentsCount" : 0,
    "shouldDisplayMessage" : false,
    "hasContent" : false
  }, {
    "name" : "function_autouse",
    "time" : {
      "start" : 1658628973258,
      "stop" : 1658628973258,
      "duration" : 0
    },
    "status" : "passed",
    "steps" : [ ],
    "attachments" : [ ],
    "parameters" : [ ],
    "stepsCount" : 0,
    "attachmentsCount" : 0,
    "shouldDisplayMessage" : false,
    "hasContent" : false
  }, {
    "name" : "testenv_setup_teardown",
    "time" : {
      "start" : 1658621560532,
      "stop" : 1658621560532,
      "duration" : 0
    },
    "status" : "passed",
    "steps" : [ ],
    "attachments" : [ ],
    "parameters" : [ ],
    "stepsCount" : 0,
    "attachmentsCount" : 0,
    "shouldDisplayMessage" : false,
    "hasContent" : false
  } ],
  "testStage" : {
    "description" : "Check that blocks were minted according to leadership schedule.\n\n        * query leadership schedule for selected pool for current epoch or next epoch\n        * wait for epoch that comes after the queried epoch\n        * get info about minted blocks in queried epoch for the selected pool\n        * compare leadership schedule with blocks that were actually minted\n        * compare db-sync records with ledger state dump\n        ",
    "status" : "failed",
    "statusMessage" : "Failed: Errors:\nSome blocks were minted in other slots than scheduled: {37507, 38023, 37129, 37770, 37262, 37774, 37775, 37270, 38044, 37278, 37407, 37154, 37538, 38054, 37288, 37934, 37936, 37553, 37811, 37558, 38071, 37304, 37947, 37316, 38086, 37977, 37217, 37353, 37100, 37357, 37491, 37876, 37623, 37371, 37243}\nLot of slots missed: {37890, 37637, 38024, 37518, 37135, 37630, 37521, 37523, 38035, 37914, 37282, 37286, 37416, 37802, 37930, 37170, 37305, 37817, 37181, 37315, 37960, 37449, 37323, 37857, 37224, 37871, 37234, 37749, 37754, 37246}",
    "statusTrace" : "self = <cardano_node_tests.tests.test_blocks.TestLeadershipSchedule object at 0x7f7201e9fa90>, skip_leadership_schedule = None\ncluster_manager = <cardano_node_tests.utils.cluster_management.ClusterManager object at 0x7f7201d490f0>, cluster_use_pool3 = <ClusterLib: protocol=cardano, tx_era=babbage>, for_epoch = 'next'\n\n    @allure.link(helpers.get_vcs_link())\n    @pytest.mark.needs_dbsync\n    @pytest.mark.parametrize(\"for_epoch\", (\"current\", \"next\"))\n    def test_pool_blocks(\n        self,\n        skip_leadership_schedule: None,\n        cluster_manager: cluster_management.ClusterManager,\n        cluster_use_pool3: clusterlib.ClusterLib,\n        for_epoch: str,\n    ):\n        \"\"\"Check that blocks were minted according to leadership schedule.\n    \n        * query leadership schedule for selected pool for current epoch or next epoch\n        * wait for epoch that comes after the queried epoch\n        * get info about minted blocks in queried epoch for the selected pool\n        * compare leadership schedule with blocks that were actually minted\n        * compare db-sync records with ledger state dump\n        \"\"\"\n        # pylint: disable=unused-argument\n        cluster = cluster_use_pool3\n        temp_template = f\"{common.get_test_id(cluster)}_{for_epoch}\"\n    \n        pool_name = cluster_management.Resources.POOL3\n        pool_rec = cluster_manager.cache.addrs_data[pool_name]\n        pool_id = cluster.get_stake_pool_id(pool_rec[\"cold_key_pair\"].vkey_file)\n    \n        if for_epoch == \"current\":\n            # wait for beginning of an epoch\n            queried_epoch = cluster.wait_for_new_epoch(padding_seconds=5)\n        else:\n            # wait for stable stake distribution for next epoch, that is last 300 slots of\n            # current epoch\n            clusterlib_utils.wait_for_epoch_interval(\n                cluster_obj=cluster,\n                start=-int(300 * cluster.slot_length),\n                stop=-10,\n                check_slot=True,\n            )\n            queried_epoch = cluster.get_epoch() + 1\n    \n        # query leadership schedule for selected pool\n        leadership_schedule = cluster.get_leadership_schedule(\n            vrf_skey_file=pool_rec[\"vrf_key_pair\"].skey_file,\n            cold_vkey_file=pool_rec[\"cold_key_pair\"].vkey_file,\n            for_next=for_epoch != \"current\",\n        )\n    \n        # wait for epoch that comes after the queried epoch\n        cluster.wait_for_new_epoch(new_epochs=1 if for_epoch == \"current\" else 2)\n    \n        # get info about minted blocks in queried epoch for the selected pool\n        minted_blocks = list(\n            dbsync_queries.query_blocks(\n                pool_id_bech32=pool_id, epoch_from=queried_epoch, epoch_to=queried_epoch\n            )\n        )\n        slots_when_minted = {r.slot_no for r in minted_blocks}\n    \n        errors: List[str] = []\n    \n        # compare leadership schedule with blocks that were actually minted\n        slots_when_scheduled = {r.slot_no for r in leadership_schedule}\n    \n        difference_scheduled = slots_when_minted.difference(slots_when_scheduled)\n        if difference_scheduled:\n            errors.append(\n                f\"Some blocks were minted in other slots than scheduled: {difference_scheduled}\"\n            )\n    \n        difference_minted = slots_when_scheduled.difference(slots_when_minted)\n        if len(difference_minted) > len(leadership_schedule) // 2:\n            errors.append(f\"Lot of slots missed: {difference_minted}\")\n    \n        # compare db-sync records with ledger state dump\n        ledger_state = clusterlib_utils.get_ledger_state(cluster_obj=cluster)\n        clusterlib_utils.save_ledger_state(\n            cluster_obj=cluster,\n            state_name=temp_template,\n            ledger_state=ledger_state,\n        )\n        blocks_before: Dict[str, int] = ledger_state[\"blocksBefore\"]\n        pool_id_dec = helpers.decode_bech32(pool_id)\n        minted_blocks_ledger = blocks_before.get(pool_id_dec) or 0\n        minted_blocks_db = len(slots_when_minted)\n        if minted_blocks_ledger != minted_blocks_db:\n            errors.append(\n                \"Numbers of minted blocks reported by ledger state and db-sync don't match: \"\n                f\"{minted_blocks_ledger} vs {minted_blocks_db}\"\n            )\n    \n        if errors:\n            err_joined = \"\\n\".join(errors)\n>           pytest.fail(f\"Errors:\\n{err_joined}\")\nE           Failed: Errors:\nE           Some blocks were minted in other slots than scheduled: {37507, 38023, 37129, 37770, 37262, 37774, 37775, 37270, 38044, 37278, 37407, 37154, 37538, 38054, 37288, 37934, 37936, 37553, 37811, 37558, 38071, 37304, 37947, 37316, 38086, 37977, 37217, 37353, 37100, 37357, 37491, 37876, 37623, 37371, 37243}\nE           Lot of slots missed: {37890, 37637, 38024, 37518, 37135, 37630, 37521, 37523, 38035, 37914, 37282, 37286, 37416, 37802, 37930, 37170, 37305, 37817, 37181, 37315, 37960, 37449, 37323, 37857, 37224, 37871, 37234, 37749, 37754, 37246}\n\n/home/martink/Source/repos/cardano-node-tests2/cardano_node_tests/tests/test_blocks.py:127: Failed",
    "steps" : [ ],
    "attachments" : [ {
      "uid" : "ac35690c7afc56ae",
      "name" : "log",
      "source" : "ac35690c7afc56ae.txt",
      "type" : "text/plain",
      "size" : 111
    } ],
    "parameters" : [ ],
    "stepsCount" : 0,
    "attachmentsCount" : 1,
    "shouldDisplayMessage" : true,
    "hasContent" : true
  },
  "afterStages" : [ {
    "name" : "close_dbconn::0",
    "time" : {
      "start" : 1658629609438,
      "stop" : 1658629609439,
      "duration" : 1
    },
    "status" : "passed",
    "steps" : [ ],
    "attachments" : [ ],
    "parameters" : [ ],
    "stepsCount" : 0,
    "attachmentsCount" : 0,
    "shouldDisplayMessage" : false,
    "hasContent" : false
  }, {
    "name" : "cluster_manager::0",
    "time" : {
      "start" : 1658629378295,
      "stop" : 1658629378299,
      "duration" : 4
    },
    "status" : "passed",
    "steps" : [ ],
    "attachments" : [ ],
    "parameters" : [ ],
    "stepsCount" : 0,
    "attachmentsCount" : 0,
    "shouldDisplayMessage" : false,
    "hasContent" : false
  }, {
    "name" : "cd_testfile_temp_dir::0",
    "time" : {
      "start" : 1658629378299,
      "stop" : 1658629378299,
      "duration" : 0
    },
    "status" : "passed",
    "steps" : [ ],
    "attachments" : [ ],
    "parameters" : [ ],
    "stepsCount" : 0,
    "attachmentsCount" : 0,
    "shouldDisplayMessage" : false,
    "hasContent" : false
  }, {
    "name" : "testenv_setup_teardown::0",
    "time" : {
      "start" : 1658629596652,
      "stop" : 1658629609438,
      "duration" : 12786
    },
    "status" : "passed",
    "steps" : [ ],
    "attachments" : [ ],
    "parameters" : [ ],
    "stepsCount" : 0,
    "attachmentsCount" : 0,
    "shouldDisplayMessage" : false,
    "hasContent" : false
  } ],
  "labels" : [ {
    "name" : "tag",
    "value" : "dbsync"
  }, {
    "name" : "tag",
    "value" : "needs_dbsync"
  }, {
    "name" : "parentSuite",
    "value" : "cardano_node_tests.tests"
  }, {
    "name" : "suite",
    "value" : "test_blocks"
  }, {
    "name" : "subSuite",
    "value" : "TestLeadershipSchedule"
  }, {
    "name" : "host",
    "value" : "bender-3900x"
  }, {
    "name" : "thread",
    "value" : "17364-MainThread"
  }, {
    "name" : "framework",
    "value" : "pytest"
  }, {
    "name" : "language",
    "value" : "cpython3"
  }, {
    "name" : "package",
    "value" : "cardano_node_tests.tests.test_blocks"
  }, {
    "name" : "resultFormat",
    "value" : "allure2"
  } ],
  "parameters" : [ {
    "name" : "for_epoch",
    "value" : "'next'"
  } ],
  "links" : [ {
    "name" : "https://github.com/input-output-hk/cardano-node-tests/blob/ed48848e8881877ef3425b7a9c3fa5bb9fb2ced8/cardano_node_tests/tests/test_blocks.py#L35",
    "url" : "https://github.com/input-output-hk/cardano-node-tests/blob/ed48848e8881877ef3425b7a9c3fa5bb9fb2ced8/cardano_node_tests/tests/test_blocks.py#L35",
    "type" : "link"
  } ],
  "hidden" : false,
  "retry" : false,
  "extra" : {
    "severity" : "normal",
    "retries" : [ {
      "uid" : "1dc3872b12539a5a",
      "status" : "skipped",
      "statusDetails" : "Skipped: collected, not run",
      "time" : {
        "start" : 1658621556416,
        "stop" : 1658621556416,
        "duration" : 0
      }
    } ],
    "categories" : [ {
      "name" : "Product defects",
      "matchedStatuses" : [ ],
      "flaky" : false
    } ],
    "tags" : [ "needs_dbsync", "dbsync" ]
  },
  "source" : "e216e68c65b5e0e4.json",
  "parameterValues" : [ "'next'" ]
}